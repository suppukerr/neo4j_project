{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/suppukerr/neo4j_project/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTAA9BWBGwxt",
        "outputId": "4e16c75f-ce73-4b99-ec9b-deacf3ec0376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'neo4j_project' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('/content/neo4j_project/pnin.pickle', 'rb') as handle:\n",
        "  book = pickle.load(handle)\n",
        "book[0] #первое предложение документа"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3qRPz8CIuSA",
        "outputId": "fcde01da-c130-489f-c719-51629350cd2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['in', 'april'],\n",
              " ['april', 'a'],\n",
              " ['a', 'brazilian'],\n",
              " ['brazilian', 'human'],\n",
              " ['human', 'right'],\n",
              " ['right', 'group'],\n",
              " ['group', 'torture'],\n",
              " ['torture', 'never'],\n",
              " ['never', 'again'],\n",
              " ['again', 'awarded'],\n",
              " ['awarded', 'the'],\n",
              " ['the', 'five'],\n",
              " ['five', 'it'],\n",
              " ['it', 'chico'],\n",
              " ['chico', 'mendes'],\n",
              " ['mendes', 'medal'],\n",
              " ['medal', 'because'],\n",
              " ['because', 'their'],\n",
              " ['their', 'right'],\n",
              " ['right', 'had'],\n",
              " ['had', 'been'],\n",
              " ['been', 'violated']]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgKjNMpO0nmi",
        "outputId": "ff4ced09-0dfa-45f4-ef79-244ab835e690"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: py2neo in /usr/local/lib/python3.9/dist-packages (2021.2.3)\n",
            "Requirement already satisfied: pygments>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from py2neo) (2.14.0)\n",
            "Requirement already satisfied: six>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from py2neo) (1.16.0)\n",
            "Requirement already satisfied: interchange~=2021.0.4 in /usr/local/lib/python3.9/dist-packages (from py2neo) (2021.0.4)\n",
            "Requirement already satisfied: monotonic in /usr/local/lib/python3.9/dist-packages (from py2neo) (1.6)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from py2neo) (2022.12.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from py2neo) (23.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from py2neo) (1.26.15)\n",
            "Requirement already satisfied: pansi>=2020.7.3 in /usr/local/lib/python3.9/dist-packages (from py2neo) (2020.7.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.9/dist-packages (from interchange~=2021.0.4->py2neo) (2022.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install py2neo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "UnnQpAP0fQx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from py2neo import Graph, Node, Relationship\n",
        "import string"
      ],
      "metadata": {
        "id": "P3IweLTt7ycD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'bolt://44.202.237.157:7687'\n",
        "\n",
        "pwd = 'radiuses-detents-seaman'"
      ],
      "metadata": {
        "id": "_2HI7tNE763c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graphnabok = Graph(url, user=\"neo4j\", password=pwd)"
      ],
      "metadata": {
        "id": "RCHh2dt2zlbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pickle\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "nltk.download('wordnet')\n",
        "patterns = \"[0-9!#$%&'()*+,./:;<=>?@[\\]^_`{|}~—\\-]+\"\n",
        "def lemmatize(doc):\n",
        "    tokens = []\n",
        "    doc = re.sub(patterns, ' ', doc)\n",
        "    for i in range(len(word_tokenize(doc)) - 1):\n",
        "        token = word_tokenize(doc)[i].strip()\n",
        "        word = token.lower()\n",
        "        token = lemmatizer.lemmatize(token)\n",
        "        next_token = word_tokenize(doc)[i+1].strip()\n",
        "        next_word = next_token.lower()\n",
        "        next_token = lemmatizer.lemmatize(next_token)\n",
        "        tokens.append([token, next_token])\n",
        "    if len(tokens) > 2:\n",
        "        return tokens\n",
        "    return None"
      ],
      "metadata": {
        "id": "iCRIIfEegrUE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecded438-650e-4472-8168-c29221afa5e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "добавляем предложения в корпус"
      ],
      "metadata": {
        "id": "pCubWJ8FQqB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_sent(punk):\n",
        "  tx = graphnabok.begin()\n",
        "  a = Node(\"Word\", word=punk[0])\n",
        "  tx.create(a)\n",
        "  b = Node(\"Word\", word=punk[1])\n",
        "  ab = Relationship(a, \"NEXT_WORD\", b)\n",
        "  tx.create(ab)\n",
        "  graphnabok.commit(tx)"
      ],
      "metadata": {
        "id": "futdKoG6Ln8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "альтернативный способ добавлять предложения в корпус"
      ],
      "metadata": {
        "id": "578Ef8AyLcAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# альтернативный способ добавлять предложения в корпус\n",
        "def add_sentence(senten):\n",
        "  tx = graphnabok.begin()\n",
        "  tx.run(\n",
        "          f'''FOREACH (t IN {senten} | \n",
        "          MERGE (w0:Word {{word: t[0]}})\n",
        "          MERGE (w1:Word {{word: t[1]}})\n",
        "          CREATE (w0)-[:NEXT_WORD]->(w1)\n",
        "          )'''\n",
        "      )\n",
        "  graphnabok.commit(tx)"
      ],
      "metadata": {
        "id": "hkL5qFAlYyKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#загрузка базы\n",
        "for punk in tqdm(book):\n",
        "  if punk is not None:\n",
        "    add_sentence(punk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "io7wJ6OMex6Z",
        "outputId": "dfd5ef0b-e135-4f20-d437-d5f23821a932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1001/1001 [17:21<00:00,  1.04s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'MATCH (n) RETURN COUNT(n)'\n",
        "result = graphnabok.query(query)\n",
        "print(result.to_data_frame())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc-KsdGtIkMK",
        "outputId": "5963bd4c-2ff8-43fa-949d-e8192aecfd6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   COUNT(n)\n",
            "0      6721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "удаление точки, отношения"
      ],
      "metadata": {
        "id": "tDMRSydIRvD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# id = 20 \n",
        "id_20 = graphnabok.evaluate(\"MATCH (n) where id(n) = 20 RETURN n\") \n",
        "# удалить точку\n",
        "graphnabok.delete(id_20)"
      ],
      "metadata": {
        "id": "0e0faMQZRsIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graphnabok.exists(id_20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skvAw9VgJ-Il",
        "outputId": "e3f4b9e7-f7c6-4ce1-846a-f70e617ab6bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "загрузка данных"
      ],
      "metadata": {
        "id": "aU71zy4Q28Hr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for punk in tqdm(sents):\n",
        "#   if punk is not None:\n",
        "#     add_sentence(lemmatize(punk))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPXc8Uj5uxAr",
        "outputId": "076007b1-f6a7-49db-9549-c09ec7e61fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6/6 [00:00<00:00, 16.47it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "берём все слова слева"
      ],
      "metadata": {
        "id": "638IF8s4Q29d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "left_query = '''\n",
        "    MATCH (s:Word {word: $word})\n",
        "    MATCH (w:Word)-[:NEXT_WORD]->(s)\n",
        "    RETURN w.word as word\n",
        "'''"
      ],
      "metadata": {
        "id": "VkUH70-HMh_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def left_context(theword):\n",
        "  ls = set()\n",
        "  tx = graphnabok.begin()\n",
        "  l = tx.run(left_query, word=theword)\n",
        "  for t in l:\n",
        "     ls.add(t['word'])\n",
        "  return ls"
      ],
      "metadata": {
        "id": "mJrhBSRNO1KD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "left_context('go')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7rb8dkBNXm-",
        "outputId": "3f7ad7da-a1d8-4395-aa44-d60c3f6b781c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'and', 'ban', 'pokemon', 'the', 'to', 'would'}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "left_context('president')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwTG8bovKeI6",
        "outputId": "fb823e87-ba41-46a2-f60a-81ce68139b98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'college',\n",
              " 'critiqued',\n",
              " 'former',\n",
              " 'general',\n",
              " 'korean',\n",
              " 'new',\n",
              " 'nra',\n",
              " 'of',\n",
              " 'removing',\n",
              " 'romanian',\n",
              " 's',\n",
              " 'the',\n",
              " 'vice'}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "берём все слова справа"
      ],
      "metadata": {
        "id": "ldtHf5aHQ7S9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "right_query = '''\n",
        "    MATCH (s:Word {word: $word})\n",
        "    MATCH (w:Word)<-[:NEXT_WORD]-(s)\n",
        "    RETURN w.word as word\n",
        "'''"
      ],
      "metadata": {
        "id": "692DH1n1Q0NH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def right_context(theword):\n",
        "  rs = set()\n",
        "  tx = graphnabok.begin()\n",
        "  r = tx.run(right_query, word=theword)\n",
        "  for s in r:\n",
        "     rs.add(s['word'])\n",
        "  return rs"
      ],
      "metadata": {
        "id": "Vcr494rhRArI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "right_context('go')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrzHMEw4NoLC",
        "outputId": "88e61a5b-9e86-41c4-a937-a4f1256c7323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'back', 'on', 'out', 'record', 'to', 'too', 'with'}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "right_context('think')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "ZRF7s4yfNoNa",
        "outputId": "facd4a71-51eb-437f-ae57-8566d461bfc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " word  | next_word | next_next_word \n",
              "-------|-----------|----------------\n",
              " think | we        | ll             \n",
              " think | we        | were           \n",
              " think | we        | typically      "
            ],
            "text/html": [
              "<table><tr><th>word</th><th>next_word</th><th>next_next_word</th></tr><tr><td style=\"text-align:left\">think</td><td style=\"text-align:left\">we</td><td style=\"text-align:left\">ll</td></tr><tr><td style=\"text-align:left\">think</td><td style=\"text-align:left\">we</td><td style=\"text-align:left\">were</td></tr><tr><td style=\"text-align:left\">think</td><td style=\"text-align:left\">we</td><td style=\"text-align:left\">typically</td></tr></table>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def jaccard_similarity(w1, w2):\n",
        "    nominator = w1.intersection(w2)\n",
        "    denominator = w1.union(w2)\n",
        "    similarity = len(nominator)/len(denominator)\n",
        "    return similarity"
      ],
      "metadata": {
        "id": "5kgXpBDUuxIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def paradigSimilarity(w1, w2):\n",
        "    return (jaccard_similarity(left_context(w1), left_context(w2)) + \n",
        "            jaccard_similarity(right_context(w1), right_context(w2))) / 2.0"
      ],
      "metadata": {
        "id": "jlO8xx3AuxKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paradigSimilarity('new', 'old')"
      ],
      "metadata": {
        "id": "YQxQTVu5J4r9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d89560f-ead5-46a2-a170-a5a00988419a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.038461538461538464"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paradigSimilarity('school', 'university')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTHDZ5ESvDKF",
        "outputId": "adb53146-fb43-45af-fa6c-682d47dda694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.016666666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "left_query_next = '''\n",
        "    MATCH (s:Word {word: $word})\n",
        "    MATCH (w:Word)-[:NEXT_WORD]->(s)\n",
        "    MATCH (d:Word)-[:NEXT_WORD]->(w)\n",
        "    RETURN d.word as prev_prev_word, w.word as prev_word, s.word as word\n",
        "'''"
      ],
      "metadata": {
        "id": "0S12HV1hqt48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def left_context_next(theword):\n",
        "  tx = graphnabok.begin()\n",
        "  l = tx.run(left_query_next, word=theword)\n",
        "  return l"
      ],
      "metadata": {
        "id": "LmgWGh_Dqw0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "left_context_next('there')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "WFzA_kPhrO5l",
        "outputId": "7638887d-3dd7-45ae-b485-74cdf0af0a87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " prev_prev_word | prev_word | word  \n",
              "----------------|-----------|-------\n",
              " exceeded       | that      | there \n",
              " accusation     | that      | there \n",
              " provided       | that      | there "
            ],
            "text/html": [
              "<table><tr><th>prev_prev_word</th><th>prev_word</th><th>word</th></tr><tr><td style=\"text-align:left\">exceeded</td><td style=\"text-align:left\">that</td><td style=\"text-align:left\">there</td></tr><tr><td style=\"text-align:left\">accusation</td><td style=\"text-align:left\">that</td><td style=\"text-align:left\">there</td></tr><tr><td style=\"text-align:left\">provided</td><td style=\"text-align:left\">that</td><td style=\"text-align:left\">there</td></tr></table>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "right_query_next = '''\n",
        "    MATCH (s:Word {word: $word})\n",
        "    MATCH (w:Word)<-[:NEXT_WORD]-(s)\n",
        "    MATCH (d:Word)<-[:NEXT_WORD]-(w)\n",
        "    RETURN s.word as word, w.word as next_word, d.word as next_next_word\n",
        "'''"
      ],
      "metadata": {
        "id": "wLCESNnQrl2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def right_context(theword):\n",
        "  tx = graphnabok.begin()\n",
        "  r = tx.run(right_query, word=theword)\n",
        "  return r"
      ],
      "metadata": {
        "id": "yEm7ptR1reli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "right_context('president')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "o9ljg34Rretc",
        "outputId": "7238c55c-e16b-46cb-edf8-4f3073795ca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " word      | next_word | next_next_word \n",
              "-----------|-----------|----------------\n",
              " president | is        | a              \n",
              " president | is        | a              \n",
              " president | is        | small          "
            ],
            "text/html": [
              "<table><tr><th>word</th><th>next_word</th><th>next_next_word</th></tr><tr><td style=\"text-align:left\">president</td><td style=\"text-align:left\">is</td><td style=\"text-align:left\">a</td></tr><tr><td style=\"text-align:left\">president</td><td style=\"text-align:left\">is</td><td style=\"text-align:left\">a</td></tr><tr><td style=\"text-align:left\">president</td><td style=\"text-align:left\">is</td><td style=\"text-align:left\">small</td></tr></table>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "both_query = '''MATCH (s:Word)\n",
        "      MATCH (w:Word)-[:NEXT_WORD]->(s)\n",
        "      WITH collect(DISTINCT w.word) as left1, s\n",
        "      RETURN left1, s\n",
        "      '''\n",
        "tx = graphnabok.begin()\n",
        "both = tx.run(both_query)\n",
        "both"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "kW2-3TZJreyj",
        "outputId": "f970154a-f6bf-47b4-b2f6-33c06f30b02b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " left1                           | s                              \n",
              "---------------------------------|--------------------------------\n",
              " ['in', 'club']                  | (_330:Word {word: 'forming'})  \n",
              " ['in', 'both', 'east', 'ghosh'] | (_1178:Word {word: 'london'})  \n",
              " ['in', 'and', 'of']             | (_4781:Word {word: 'certain'}) "
            ],
            "text/html": [
              "<table><tr><th>left1</th><th>s</th></tr><tr><td style=\"text-align:left\">[&#039;in&#039;, &#039;club&#039;]</td><td style=\"text-align:left\">(_330:Word {word: &#039;forming&#039;})</td></tr><tr><td style=\"text-align:left\">[&#039;in&#039;, &#039;both&#039;, &#039;east&#039;, &#039;ghosh&#039;]</td><td style=\"text-align:left\">(_1178:Word {word: &#039;london&#039;})</td></tr><tr><td style=\"text-align:left\">[&#039;in&#039;, &#039;and&#039;, &#039;of&#039;]</td><td style=\"text-align:left\">(_4781:Word {word: &#039;certain&#039;})</td></tr></table>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Наработки"
      ],
      "metadata": {
        "id": "5gDT6Bm6J5zU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sim_query = '''\n",
        "MATCH (s:Word)\n",
        "// правый и левый контексты, собираем их\n",
        "MATCH (w:Word)-[:NEXT_WORD]->(s)\n",
        "WITH collect(DISTINCT w.word) as left1, s\n",
        "MATCH (w:Word)<-[:NEXT_WORD]-(s)\n",
        "WITH left1, s, collect(DISTINCT w.word) as right1\n",
        "// собираем все остальные слова, отличные от центрального -- искомого слова\n",
        "MATCH (o:Word) WHERE NOT s = o\n",
        "WITH left1, right1, s, o\n",
        "// берём следующие правые и следующие левые\n",
        "MATCH (w:Word)-[:NEXT_WORD]->(o)\n",
        "WITH collect(DISTINCT w.word) as left1_o, s, o, right1, left1\n",
        "MATCH (w:Word)<-[:NEXT_WORD]-(o)\n",
        "WITH left1_o, s, o, right1, left1, collect(DISTINCT w.word) as right1_o\n",
        "// считаем юнион интесект справа\n",
        "WITH FILTER(x IN right1 WHERE x IN right1_o) as r1_intersect,\n",
        "  (right1 + right1_o) AS r1_union, s, o, right1, left1, right1_o, left1_o\n",
        "// считаем юнион интесект слева\n",
        "WITH FILTER(x IN left1 WHERE x IN left1_o) as l1_intersect,\n",
        "  (left1 + left1_o) AS l1_union, r1_intersect, r1_union, s, o\n",
        "WITH DISTINCT r1_union as r1_union, l1_union as l1_union, r1_intersect, l1_intersect, s, o\n",
        "//считаем по формуле джаккарда\n",
        "WITH 1.0*length(r1_intersect) / length(r1_union) as r1_jaccard,\n",
        "  1.0*length(l1_intersect) / length(l1_union) as l1_jaccard,\n",
        "  s, o\n",
        "WITH s, o, r1_jaccard, l1_jaccard, r1_jaccard + l1_jaccard as sim\n",
        "//задаём это как отношение и самостоятельное значение\n",
        "CREATE UNIQUE (s)-[r:RELATED_TO]->(o) SET r.paradig = sim;\n",
        "'''\n",
        "\n",
        "tx = graphnabok.begin()\n",
        "tx.run(sim_query)"
      ],
      "metadata": {
        "id": "6hsUt9qhsYZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "выдать наиболее похожие друг на друга по симиларити"
      ],
      "metadata": {
        "id": "RkaiAhxa6ND_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "check_query = '''MATCH (s)-[r:RELATED_TO]->(o) \n",
        "RETURN s.word,o.word,r.paradig AS sim ORDER BY sim DESC LIMIT 100;\n",
        "'''\n",
        "tx = graphnabok.begin()\n",
        "tx.run(check_query)"
      ],
      "metadata": {
        "id": "oxjcAE-niVzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Upl7swEJv8WP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#удалить всё\n",
        "graphnabok.delete_all()"
      ],
      "metadata": {
        "id": "EBLAjHfxbLWq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}